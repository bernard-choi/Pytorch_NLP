{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with CNN(MNIST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\wheel\\pep425tags.py:75: RuntimeWarning: Config variable 'Py_DEBUG' is unset, Python ABI tag may be incorrect\n",
      "  warn=(impl == 'cp')):\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\wheel\\pep425tags.py:79: RuntimeWarning: Config variable 'WITH_PYMALLOC' is unset, Python ABI tag may be incorrect\n",
      "  warn=(impl == 'cp')):\n",
      "torch-0.4.1-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\n",
      "You are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.device()를 통해 gpu를 이용합니다. \n",
    "# cuda:뒤의 번호는 gpu를 여러개 동시 사용할 때 쓰이는 gpu 번호입니다.\n",
    "# gpu 사용이 가능한 경우 torch.cuda.is_available() = True이고 아닌 경우 False가 됩니다.\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter들을 설정합니다.\n",
    "\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset을 불러옵니다.\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader를 이용해 batch_size만큼 데이터를 불러올 수 있도록 합니다.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes = 10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # conv2d 에서는 28X28 그대로 나온다\n",
    "        # pooling을 통해 size는 14 X 14가 된다\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,kernel_size=5, stride = 1, padding = 2),\n",
    "            nn.BatchNorm2d(num_features = 16), ## batchnorm은 activation function 전에 넣는다\n",
    "            nn.ReLU(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "            )\n",
    "        \n",
    "        # conv2d에서는 14 X 14 그대로 나옵니다. \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32,kernel_size = 5, stride = 1, padding = 2),\n",
    "            nn.BatchNorm2d(num_features = 32), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            )\n",
    "        \n",
    "        self.fc = nn.Linear(7*7*32,num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.reshape(x.size(0),-1) # batchsize를 제외한 나머지 \n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "    \n",
    "model = ConvNet(num_classes).to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600],Loss: 0.1244\n",
      "Epoch [1/5], Step [200/600],Loss: 0.1054\n",
      "Epoch [1/5], Step [300/600],Loss: 0.1559\n",
      "Epoch [1/5], Step [400/600],Loss: 0.1193\n",
      "Epoch [1/5], Step [500/600],Loss: 0.0897\n",
      "Epoch [1/5], Step [600/600],Loss: 0.0701\n",
      "Epoch [2/5], Step [100/600],Loss: 0.0504\n",
      "Epoch [2/5], Step [200/600],Loss: 0.0898\n",
      "Epoch [2/5], Step [300/600],Loss: 0.0318\n",
      "Epoch [2/5], Step [400/600],Loss: 0.0472\n",
      "Epoch [2/5], Step [500/600],Loss: 0.0389\n",
      "Epoch [2/5], Step [600/600],Loss: 0.0464\n",
      "Epoch [3/5], Step [100/600],Loss: 0.0104\n",
      "Epoch [3/5], Step [200/600],Loss: 0.0581\n",
      "Epoch [3/5], Step [300/600],Loss: 0.0576\n",
      "Epoch [3/5], Step [400/600],Loss: 0.0247\n",
      "Epoch [3/5], Step [500/600],Loss: 0.0747\n",
      "Epoch [3/5], Step [600/600],Loss: 0.0930\n",
      "Epoch [4/5], Step [100/600],Loss: 0.0242\n",
      "Epoch [4/5], Step [200/600],Loss: 0.0401\n",
      "Epoch [4/5], Step [300/600],Loss: 0.0279\n",
      "Epoch [4/5], Step [400/600],Loss: 0.0121\n",
      "Epoch [4/5], Step [500/600],Loss: 0.0283\n",
      "Epoch [4/5], Step [600/600],Loss: 0.0126\n",
      "Epoch [5/5], Step [100/600],Loss: 0.0294\n",
      "Epoch [5/5], Step [200/600],Loss: 0.0184\n",
      "Epoch [5/5], Step [300/600],Loss: 0.0198\n",
      "Epoch [5/5], Step [400/600],Loss: 0.0321\n",
      "Epoch [5/5], Step [500/600],Loss: 0.0087\n",
      "Epoch [5/5], Step [600/600],Loss: 0.0649\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader): ## 데이터 600개에서 100새개씩\n",
    "        images = images.to(device)                      ## i는 인덱스(0 ~ 600)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}],Loss: {:.4f}'\n",
    "                  .format(epoch+1,num_epochs, i+1, total_step,loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.82 %\n"
     ]
    }
   ],
   "source": [
    "# eval() 에서는 dropout, batchnorm등의 동작이 다릅니다.\n",
    "# dropout은 작동되지 않고 batchnorm의 running_mean, running_std는 normalization을 위해 사용 됩니다.\n",
    "# 자세한 내용은 torch.nn.BatchNorm2d()을 참조\n",
    "# torch.no_grad() autograd가 작동하지 않도록 해서 메모리를 줄이고 속도를 높인다\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
