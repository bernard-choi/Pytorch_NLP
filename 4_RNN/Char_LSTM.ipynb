{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"hello pytorch. how long can a rnn cell remember? show me your limit!\"\n",
    "chars = \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n",
    "char_list = [i for i in chars]\n",
    "char_len = len(char_list)\n",
    "\n",
    "char_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seq_len = 1\n",
    "num_layers = 1\n",
    "input_size = char_len\n",
    "hidden_size = 35 \n",
    "lr = 0.01\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) String to One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String to onehot vector\n",
    "# a -> [1 0 0 ... 0 0]\n",
    "\n",
    "def string_to_onehot(string):\n",
    "    start = np.zeros(shape=len(char_list) ,dtype=int)\n",
    "    end = np.zeros(shape=len(char_list) ,dtype=int)\n",
    "    start[-2] = 1\n",
    "    end[-1] = 1\n",
    "    for i in string:\n",
    "        idx = char_list.index(i)\n",
    "        zero = np.zeros(shape=char_len ,dtype=int)\n",
    "        zero[idx]=1\n",
    "        start = np.vstack([start,zero])\n",
    "    output = np.vstack([start,end])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Onehot to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot vector to word\n",
    "# [1 0 0 ... 0 0] -> a \n",
    "\n",
    "def onehot_to_word(onehot_1):\n",
    "    onehot = torch.Tensor(onehot_1)\n",
    "    return char_list[onehot.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = string_to_onehot(string)[0]\n",
    "onehot_to_word(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = string_to_onehot(string)[1]\n",
    "onehot_to_word(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = string_to_onehot(string)[2]\n",
    "onehot_to_word(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN with 1 hiddden layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        \n",
    "    def forward(self, input, hidden, cell): ## LSTM이라서 hidden이랑 cell state\n",
    "        output, (hidden,cell) = self.lstm(input,(hidden,cell))\n",
    "        \n",
    "        return output,hidden,cell\n",
    "    \n",
    "    def init_hidden_cell(self):\n",
    "        hidden = Variable(torch.zeros(num_layers,seq_len*batch_size,hidden_size))\n",
    "        cell = Variable(torch.zeros(num_layers, seq_len*batch_size,hidden_size))\n",
    "        \n",
    "        return hidden, cell\n",
    "    \n",
    "rnn = RNN(input_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loss Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 35])\n"
     ]
    }
   ],
   "source": [
    "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
    "print(one_hot.size())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 35])\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "input_data = Variable(one_hot[j:j+seq_len].view(batch_size,seq_len,-1))\n",
    "print(input_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 35]) torch.Size([1, 1, 35])\n"
     ]
    }
   ],
   "source": [
    "hidden,  cell = rnn.init_hidden_cell()\n",
    "print(hidden.size(), cell.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 35]) torch.Size([1, 1, 35]) torch.Size([1, 1, 35])\n"
     ]
    }
   ],
   "source": [
    "output, hidden, cell = rnn(input_data, hidden, cell)\n",
    "print(output.size(), hidden.size(), cell.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string) + 2 # start 랑 end 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "unroll_len = one_hot.size()[0] // seq_len -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unroll_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6163, grad_fn=<AddBackward0>)\n",
      "tensor(1.7552, grad_fn=<AddBackward0>)\n",
      "tensor(1.3937, grad_fn=<AddBackward0>)\n",
      "tensor(1.1782, grad_fn=<AddBackward0>)\n",
      "tensor(1.0341, grad_fn=<AddBackward0>)\n",
      "tensor(0.9346, grad_fn=<AddBackward0>)\n",
      "tensor(0.8486, grad_fn=<AddBackward0>)\n",
      "tensor(0.7642, grad_fn=<AddBackward0>)\n",
      "tensor(0.6746, grad_fn=<AddBackward0>)\n",
      "tensor(0.6018, grad_fn=<AddBackward0>)\n",
      "tensor(0.5405, grad_fn=<AddBackward0>)\n",
      "tensor(0.5023, grad_fn=<AddBackward0>)\n",
      "tensor(0.4521, grad_fn=<AddBackward0>)\n",
      "tensor(0.4192, grad_fn=<AddBackward0>)\n",
      "tensor(0.3906, grad_fn=<AddBackward0>)\n",
      "tensor(0.3669, grad_fn=<AddBackward0>)\n",
      "tensor(0.3455, grad_fn=<AddBackward0>)\n",
      "tensor(0.3237, grad_fn=<AddBackward0>)\n",
      "tensor(0.3046, grad_fn=<AddBackward0>)\n",
      "tensor(0.2856, grad_fn=<AddBackward0>)\n",
      "tensor(0.2707, grad_fn=<AddBackward0>)\n",
      "tensor(0.2555, grad_fn=<AddBackward0>)\n",
      "tensor(0.2434, grad_fn=<AddBackward0>)\n",
      "tensor(0.2363, grad_fn=<AddBackward0>)\n",
      "tensor(0.2252, grad_fn=<AddBackward0>)\n",
      "tensor(0.2164, grad_fn=<AddBackward0>)\n",
      "tensor(0.2094, grad_fn=<AddBackward0>)\n",
      "tensor(0.2033, grad_fn=<AddBackward0>)\n",
      "tensor(0.1976, grad_fn=<AddBackward0>)\n",
      "tensor(0.1954, grad_fn=<AddBackward0>)\n",
      "tensor(0.1992, grad_fn=<AddBackward0>)\n",
      "tensor(0.1904, grad_fn=<AddBackward0>)\n",
      "tensor(0.1818, grad_fn=<AddBackward0>)\n",
      "tensor(0.1765, grad_fn=<AddBackward0>)\n",
      "tensor(0.1722, grad_fn=<AddBackward0>)\n",
      "tensor(0.1684, grad_fn=<AddBackward0>)\n",
      "tensor(0.1650, grad_fn=<AddBackward0>)\n",
      "tensor(0.1618, grad_fn=<AddBackward0>)\n",
      "tensor(0.1589, grad_fn=<AddBackward0>)\n",
      "tensor(0.1634, grad_fn=<AddBackward0>)\n",
      "tensor(0.1555, grad_fn=<AddBackward0>)\n",
      "tensor(0.1523, grad_fn=<AddBackward0>)\n",
      "tensor(0.1492, grad_fn=<AddBackward0>)\n",
      "tensor(0.1467, grad_fn=<AddBackward0>)\n",
      "tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "tensor(0.1364, grad_fn=<AddBackward0>)\n",
      "tensor(0.1324, grad_fn=<AddBackward0>)\n",
      "tensor(0.1290, grad_fn=<AddBackward0>)\n",
      "tensor(0.1260, grad_fn=<AddBackward0>)\n",
      "tensor(0.1237, grad_fn=<AddBackward0>)\n",
      "tensor(0.1162, grad_fn=<AddBackward0>)\n",
      "tensor(0.1114, grad_fn=<AddBackward0>)\n",
      "tensor(0.1084, grad_fn=<AddBackward0>)\n",
      "tensor(0.1061, grad_fn=<AddBackward0>)\n",
      "tensor(0.1074, grad_fn=<AddBackward0>)\n",
      "tensor(0.1046, grad_fn=<AddBackward0>)\n",
      "tensor(0.1015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "tensor(0.0997, grad_fn=<AddBackward0>)\n",
      "tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "tensor(0.0684, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = rnn.init_hidden_cell()\n",
    "    loss= 0\n",
    "    \n",
    "    for i in range(unroll_len):\n",
    "        input_data = Variable(one_hot[i:i+seq_len].view(batch_size,seq_len,-1))\n",
    "        label = Variable(one_hot[i+1:i+seq_len+1].view(batch_size,seq_len,-1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, hidden, cell = rnn(input_data, hidden, cell)\n",
    "        loss += criterion(output.view(1,-1),label.view(1,-1))\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello pytorch. how long can a rnn cell remember? show me your limit!"
     ]
    }
   ],
   "source": [
    "hidden, cell = rnn.init_hidden_cell()\n",
    "\n",
    "for j in range(unroll_len-1):\n",
    "    input_data = Variable(one_hot[j:j+seq_len].view(batch_size, seq_len,-1))\n",
    "    label = Variable(one_hot[j+1:j+seq_len+1].view(batch_size,seq_len,-1))\n",
    "    \n",
    "    output, hidden, cell = rnn(input_data, hidden,cell)\n",
    "    print(onehot_to_word(output.data), end = \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
