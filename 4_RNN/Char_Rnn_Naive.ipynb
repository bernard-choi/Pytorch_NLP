{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "embedding_size = 150  \n",
    "hidden_size = 100\n",
    "batch_size =1\n",
    "num_layers = 1\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "### 1) Prepare characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 1115394\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./data/shakespeare.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions for text processing\n",
    "### 1) Random Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ou livest and breathest,\n",
      "Yet art thou slain in him: thou dost consent\n",
      "In some large measure to thy father's death,\n",
      "In that thou seest thy wretched brother die,\n",
      "Who was the model of thy father's life.\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "def random_chunk(): ## 세익스피어 뭉치에서 chunk_len 200만큼 랜덤으로 텍스트 추출\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Character to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([34, 30, 23, 28, 18, 20, 30, 28])\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(char_tensor('yunsikus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters.index('yunsiks'[0]) ## y의 인덱스가 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Chink into input & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp,target = random_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 21, 14, 77, 96, 37, 14, 21, 18, 20, 14, 94, 34, 24, 30, 94, 22, 14,\n",
       "        10, 23, 94, 29, 24, 94, 22, 10, 20, 14, 94, 10, 94, 25, 30, 25, 25, 14,\n",
       "        29, 94, 24, 15, 94, 22, 14, 75, 96, 96, 51, 40, 55, 53, 56, 38, 43, 44,\n",
       "        50, 77, 96, 58, 17, 34, 73, 94, 29, 27, 30, 14, 78, 94, 17, 14, 94, 22,\n",
       "        14, 10, 23, 28, 94, 29, 24, 94, 22, 10, 20, 14, 94, 10, 94, 25, 30, 25,\n",
       "        25, 14, 29, 94, 24, 15, 94, 29, 17, 14, 14, 75, 96, 96, 55, 10, 18, 21,\n",
       "        24, 27, 77, 96, 54, 17, 14, 94, 28, 10, 34, 28, 94, 34, 24, 30, 27, 94,\n",
       "        32, 24, 27, 28, 17, 18, 25, 94, 22, 14, 10, 23, 28, 94, 29, 24, 94, 22,\n",
       "        10, 20, 14, 96, 10, 94, 25, 30, 25, 25, 14, 29, 94, 24, 15, 94, 17, 14,\n",
       "        27, 75, 96, 96, 51, 40, 55, 53, 56, 38, 43, 44, 50, 77, 96, 50, 94, 22,\n",
       "        24, 23, 28, 29, 27, 24, 30, 28, 94, 10, 27, 27, 24, 16, 10, 23, 12, 14,\n",
       "        62, 94])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 14, 77, 96, 37, 14, 21, 18, 20, 14, 94, 34, 24, 30, 94, 22, 14, 10,\n",
       "        23, 94, 29, 24, 94, 22, 10, 20, 14, 94, 10, 94, 25, 30, 25, 25, 14, 29,\n",
       "        94, 24, 15, 94, 22, 14, 75, 96, 96, 51, 40, 55, 53, 56, 38, 43, 44, 50,\n",
       "        77, 96, 58, 17, 34, 73, 94, 29, 27, 30, 14, 78, 94, 17, 14, 94, 22, 14,\n",
       "        10, 23, 28, 94, 29, 24, 94, 22, 10, 20, 14, 94, 10, 94, 25, 30, 25, 25,\n",
       "        14, 29, 94, 24, 15, 94, 29, 17, 14, 14, 75, 96, 96, 55, 10, 18, 21, 24,\n",
       "        27, 77, 96, 54, 17, 14, 94, 28, 10, 34, 28, 94, 34, 24, 30, 27, 94, 32,\n",
       "        24, 27, 28, 17, 18, 25, 94, 22, 14, 10, 23, 28, 94, 29, 24, 94, 22, 10,\n",
       "        20, 14, 96, 10, 94, 25, 30, 25, 25, 14, 29, 94, 24, 15, 94, 17, 14, 27,\n",
       "        75, 96, 96, 51, 40, 55, 53, 56, 38, 43, 44, 50, 77, 96, 50, 94, 22, 24,\n",
       "        23, 28, 29, 27, 24, 30, 28, 94, 10, 27, 27, 24, 16, 10, 23, 12, 14, 62,\n",
       "        94, 55])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,embedding_size,hidden_size,output_size,num_layers=1):\n",
    "        super(RNN,self).__init__()\n",
    "        self.input_size = input_size ## 35\n",
    "        self.hidden_size = hidden_size ## 100\n",
    "        self.output_size = output_size\n",
    "        self.num_layers= num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden= Variable(torch.zeros(self.num_layers, batch_size, hidden_size))\n",
    "        return hidden\n",
    "    \n",
    "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers=1)\n",
    "        ## 2번쨰 n_characters는 outputsize랑 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36])\n",
      "torch.Size([1, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())  ## num_layers, batch_size, hidden_size\n",
    "\n",
    "out, hidden = model(inp,hidden)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(59)\n"
     ]
    }
   ],
   "source": [
    "start_str = \"b\" ## b로 시작 이것도 확률분포로 만들 수 있지 않을까?\n",
    "inp = char_tensor(start_str)\n",
    "hidden = model.init_hidden()\n",
    "x = inp\n",
    "for i in range(1):\n",
    "    output, hidden = model(x,hidden)\n",
    "    output_dist = output.data.view(-1).div(0.8).exp()    \n",
    "    top_i = torch.multinomial(output_dist,1)[0]\n",
    "    print(top_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7439, 1.5146, 1.1236, 0.7769, 2.1880, 0.6666, 1.4492, 0.5392, 0.9635,\n",
       "        0.7870, 1.3467, 0.8468, 0.7555, 0.8428, 0.7420, 1.4124, 0.7087, 1.8945,\n",
       "        1.6752, 0.6588, 0.6291, 0.8761, 1.1234, 1.6576, 1.1545, 0.9888, 1.4553,\n",
       "        0.8164, 0.8039, 0.8709, 1.2871, 0.8534, 2.0909, 0.6292, 0.6667, 0.7503,\n",
       "        1.0221, 1.1365, 0.4136, 0.8479, 0.6134, 0.8297, 0.9006, 0.8570, 0.8674,\n",
       "        1.6810, 1.1234, 1.7378, 0.6311, 0.8464, 1.3804, 0.4324, 0.8817, 0.6774,\n",
       "        0.6859, 0.7459, 0.5737, 0.6090, 0.7238, 0.9889, 0.5957, 1.7250, 0.9680,\n",
       "        1.3992, 0.9207, 0.5543, 0.7294, 0.8411, 0.9374, 1.4614, 0.5707, 0.6041,\n",
       "        0.7772, 1.0397, 0.6279, 1.0685, 1.0852, 1.7853, 0.8995, 1.4530, 1.2192,\n",
       "        1.1256, 1.6676, 0.6446, 1.2014, 0.9949, 0.4919, 1.2112, 0.8351, 0.7915,\n",
       "        1.1694, 1.0610, 1.0368, 1.5040, 1.0098, 1.4726, 1.6508, 0.8255, 0.6520,\n",
       "        0.8373])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(1):\n",
    "        x = inp[i]\n",
    "        y_ = label[i]\n",
    "        y,hidden = model(x,hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1408,  0.7188,  0.5278, -0.0148, -0.5549, -0.8979, -0.5828,\n",
       "          -0.5003, -0.7104,  0.0867,  0.4030, -0.0624,  0.5574,  0.1014,\n",
       "          -0.2588, -0.0042,  0.4902, -0.3436,  0.5033, -0.2718, -0.4009,\n",
       "          -0.3011,  0.2921, -0.4843,  0.6959,  0.8544,  0.0139, -0.0100,\n",
       "           0.1575, -0.7728,  0.1670, -0.2857, -0.0505, -0.7432, -0.1427,\n",
       "          -0.6114, -0.8402,  0.1639, -0.3281,  0.4113, -0.4486,  0.9151,\n",
       "          -0.4658, -0.4356, -0.8988,  0.5342,  0.3038, -0.6788, -0.0262,\n",
       "          -0.7841,  0.8736, -0.0173, -0.7930,  0.1247,  0.8178, -0.6351,\n",
       "           0.7127,  0.3769,  0.5729,  0.4580, -0.8677, -0.4816,  0.1188,\n",
       "          -0.9233,  0.7388, -0.2918,  0.1238, -0.2786, -0.5910,  0.2711,\n",
       "          -0.8166,  0.7907,  0.8036, -0.2333,  0.0796,  0.4989, -0.5476,\n",
       "          -0.3519, -0.6112, -0.8517, -0.1181, -0.4000,  0.6478,  0.2811,\n",
       "          -0.3273, -0.8308,  0.0569, -0.1781,  0.7788,  0.2830, -0.1876,\n",
       "           0.8917, -0.3329, -0.7990,  0.8055,  0.6447, -0.2096,  0.3413,\n",
       "          -0.5871,  0.1117]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor(4.6694, grad_fn=<DivBackward0>) \n",
      "\n",
      "b28EJp3\\]v\"7~ki_w1nDqCW\\|Ny<EC%CBj>hSZ}pH0'RxBZ7bl.x2\f",
      "!(?p(_l} .pAO# zTtJbe#\\=\"Y|uFV>I,U6A4iZqIMMF5zD{V\tM`[-%%NQj;&3@&oJ=`h&:!CX^Q$~'x:\u000b",
      "&zycNu*TNP+[mT`JCd6,^7`;R{P!ccGcWnB~3y[~`|gn86!TM[Y:CLcm\\e na7!zE\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.4487, grad_fn=<DivBackward0>) \n",
      "\n",
      "boud tamnd, filly hat hars, te ceot be weth pfndt oist oou? gart t thepis, serss, he' yse tnen ho, sit ond the thar he tsenceaof th th men, se soram oo Ren tors owetry sises, vit le he done cher ouan s\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.1592, grad_fn=<DivBackward0>) \n",
      "\n",
      "brithe nate on.\n",
      "\n",
      "Sent ifeber thald Iup bent Wid tor hath thard the bred no higm my urther'd the of ye I wad not med at 'the kit, hor ife of bin hear ofy\n",
      "Tham wiles mesit in sreancelyeW, that brit the m\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.1907, grad_fn=<DivBackward0>) \n",
      "\n",
      "bly! thur wheis you mum prears his nowe derding mymenacin monted for hit oiter my do ford will all youd sthes Gors.\n",
      "\n",
      "BY\n",
      "And I speerve?\n",
      "\n",
      "IOLANUCACANUS:\n",
      "Lut fravald serke havenath'ded haste me hest to th\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.1104, grad_fn=<DivBackward0>) \n",
      "\n",
      "ble bay but Fhe to thes and wast ntel hat maulth are me themse mares? all wone bard, ander weed and to the dat to ther:\n",
      "Therbull sere thes fave so to hellf.\n",
      "\n",
      "CUKINGSAR\n",
      "Ye to sty be.\n",
      "\n",
      "LUMINCE HENMERO:\n",
      "W\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.1498, grad_fn=<DivBackward0>) \n",
      "\n",
      "but ther an't the the that mens. Go dotpet teat cof in with\n",
      "You ther that the all frome thors on hace. The cone sol with\n",
      "Thonce the that mandent to thot bell wand the frote your your yours wer' to pome\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9745, grad_fn=<DivBackward0>) \n",
      "\n",
      "bllou?\n",
      " havence thou how to now then tere! to old no so pries\n",
      "Vake mon,\n",
      "Wot me cill'd do to to the wist\n",
      "I sood should thif but, a heed at thes's frim;\n",
      "Riblop wous the kis senfance\n",
      "You hak to not Pit;\n",
      "A\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7978, grad_fn=<DivBackward0>) \n",
      "\n",
      "bening; what be to unster hill hal waur of epter.\n",
      "\n",
      "IULIA:\n",
      "I do aild will his what my ford will and whet in the hombo ur wigh will bet and thall aling bet my mest she thou a in teere and how thiot!\n",
      "Sa n\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.3189, grad_fn=<DivBackward0>) \n",
      "\n",
      "bet him the were hich a pass the haster mard minger,\n",
      "As dost meeser this muher?\n",
      "As sead mast this theer my mise make then thou nod me to live tithing hough inos.\n",
      "\n",
      "Fome:\n",
      "Ah the suses! Sing me dealt of t\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8802, grad_fn=<DivBackward0>) \n",
      "\n",
      "ble caod not to soon he it,\n",
      "ADt to me woy shis this foraven maint a a preves, folly ines stany that and tralling fortio for cone must more than,\n",
      "Whed if not seombant sord of it the tor the munts rean d\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.0263, grad_fn=<DivBackward0>) \n",
      "\n",
      "breecty crowe, may, why manthed;\n",
      "And Cyour,\n",
      "And then shathsponged an the man:\n",
      "Than Ras thee, sood many fue a may, be that you, thou have lome'd by miever'der, you coure meensed the beallienth, aft whys\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.0039, grad_fn=<DivBackward0>) \n",
      "\n",
      "bod mole's the well's enduse the thus for bof well,\n",
      "And brey's his with it live the wist dearvech in hould his, priour our man thy, brest the here fishoms!\n",
      "And you thou you, king thou rech under eving \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9427, grad_fn=<DivBackward0>) \n",
      "\n",
      "be mest,\n",
      "Sing, four should serow sheen: so wentes of can\n",
      "I I'll wall sid dreath what thou a poo hers.\n",
      "\n",
      "AULIO:\n",
      "Torselpittreforty--heepingter.\n",
      "\n",
      "Buston, and whis teames coness,\n",
      "cold is go 'to for reepuse,\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7823, grad_fn=<DivBackward0>) \n",
      "\n",
      "belonhing not his, and a deen, I'll come and I hand,\n",
      "At should may jost:\n",
      "To the stime;\n",
      "Sores, suided bones!\n",
      "me:\n",
      "The cain:\n",
      "Rothen'd on heart\n",
      "These's on sonour the murse will fare but whou havirke the hi\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9568, grad_fn=<DivBackward0>) \n",
      "\n",
      "bely make frother the lather a him my virst of worder curnino neefur of dematt the wish whof een a see rever'd lorles\n",
      "\n",
      "Firk rastith and In the lever our the rumbrave conds he sold agould of auth latens\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.0634, grad_fn=<DivBackward0>) \n",
      "\n",
      "ben cetrand that the remoth a me parts for dower tell the cane neath but than sir sone\n",
      "Herss as hew Rilint at grain. That thelliok, never larsuthail, himb aghy you ay pords, aul will that with re the p\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9797, grad_fn=<DivBackward0>) \n",
      "\n",
      "blat court a congues of the lith's would or boor him.\n",
      "\n",
      "Bure! as hear would of he how of my good the mose that be go me the of I huse good, menter bath in down up com the stright enous of the to the con\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8881, grad_fn=<DivBackward0>) \n",
      "\n",
      "bodchold me arould in made the lice.\n",
      "\n",
      "Simes to where as but greet with all wataum, and I plant, and the aly of with my to and in mistry vyow you the tright tho thid the not not comper, breat hive the a\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9923, grad_fn=<DivBackward0>) \n",
      "\n",
      "belmendy\n",
      "So that sold bath the our the lord!\n",
      "\n",
      "LOLANT:\n",
      "No the worghest you wretand doant would you with wifues\n",
      "Orour\n",
      "And Menouping and sirs.\n",
      "\n",
      "Lome,\n",
      "As not in,--Gous oad there for I spoy frinch how weren\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7644, grad_fn=<DivBackward0>) \n",
      "\n",
      "bed Suster thy,\n",
      "Your truch tre tell a waunt of sence, that to for food, I'll low the son: you will be of hath walthles not the the sine thou? have\n",
      "Well lows are cold?\n",
      "\n",
      "LADY CULELANCAP:\n",
      "And dequent me t\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5091, grad_fn=<DivBackward0>) \n",
      "\n",
      "blime I that is my with the as the forself and in on plion!\n",
      "\n",
      "Sire crud and with and what were thou sir; fears of this pads and me to he frosses astitiembly, brience he confor she remers in your cound f\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6564, grad_fn=<DivBackward0>) \n",
      "\n",
      "be I vood hand the your like.\n",
      "\n",
      "KING OF YORD AVSSLASTORIO:\n",
      "For pross a prite ince had, in mene ance ureak me ale mis brizen:\n",
      "Shere to theettt Jut ser the heart and bloth'd the, a pion me spown Lord and \n",
      "\n",
      "\n",
      "\n",
      " tensor(2.0141, grad_fn=<DivBackward0>) \n",
      "\n",
      "ble?\n",
      "\n",
      "CORIET:\n",
      "We piint.\n",
      "\n",
      "CORIO:\n",
      "I cound: and well, aglelp, and hor with light, sould be with shards us bath, the frid, we hadce\n",
      "And mine, seath,\n",
      "By the past, shall hough man.\n",
      "\n",
      "LUCKIAN:\n",
      "\n",
      "MEREY:\n",
      "Yous hea\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5515, grad_fn=<DivBackward0>) \n",
      "\n",
      "bours come\n",
      "Thy pright'd\n",
      "Thou were the bether: we of.\n",
      "\n",
      "BAUDIO:\n",
      "Petweed good have foods, thy wrip; hew leath\n",
      "O, him that fore in theet of him your tell there unteeped hould more is are on, coman that in \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7626, grad_fn=<DivBackward0>) \n",
      "\n",
      "bed do notese\n",
      "As Lord:\n",
      "How dois?\n",
      "\n",
      "CLARINA:\n",
      "Let fathis.\n",
      "\n",
      "LOLIO:\n",
      "And bost\n",
      "That mast of in ofout the saire hear his ford:\n",
      "And of prish;\n",
      "And thou the prom this it.\n",
      "And gousitime this hord is\n",
      "Your a she row\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6813, grad_fn=<DivBackward0>) \n",
      "\n",
      "band thy gervin, I shath your from it lest this with dike 'thy him hold that now the death wast I plailt think kencetty your froth in\n",
      "And say\n",
      "How thou lith nast spentarm dain breathatiand have sever wi\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7165, grad_fn=<DivBackward0>) \n",
      "\n",
      "bad\n",
      "The for to aget our hope other chund come he madimon, made combly douse seed dighed in to my Hadin--had the kirst he kird for card, in I hark with have of hear\n",
      "It my crompory\n",
      "is are ear worder more\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9790, grad_fn=<DivBackward0>) \n",
      "\n",
      "blest the refood this offen in to spud, and not to expices his home dishal-sown may instrue comman:\n",
      "Whou sweatt I wither the shear of he dreak.\n",
      "\n",
      "RIVIO:\n",
      "Let thee crome; and will ones to sentle are with \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7334, grad_fn=<DivBackward0>) \n",
      "\n",
      "bainn, fondenty nepes: and musdiel:\n",
      "meed it holes have lived to so you have all if the ears my cray the pray can to bedatuandy!\n",
      "\n",
      "Secauniared that to the have my himself the made.\n",
      "Word,\n",
      "I'll brom of roo\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8503, grad_fn=<DivBackward0>) \n",
      "\n",
      "bor of his that say mingerer not a his doan in combleloun a pull abay.\n",
      "\n",
      "TING ENCE:\n",
      "And entises a glan'st\n",
      "The bloid to seacks;\n",
      "And bed.\n",
      "\n",
      "TUCHARD IV:\n",
      "This not.\n",
      "Ay, all thangs:\n",
      "Why, be unterves,\n",
      "That my b\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9068, grad_fn=<DivBackward0>) \n",
      "\n",
      "battle he pariend do wifest me uppent dastines.\n",
      "\n",
      "Feck and, frong, 'twill now, where and dear down\n",
      "To worgent the hath me the have farman:\n",
      "And the noed not fors is druth for, and the not\n",
      "My but to dean \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9564, grad_fn=<DivBackward0>) \n",
      "\n",
      "be?\n",
      "\n",
      "YORK:\n",
      "And my tame my speart, yours dame, true hale with with be the ruck,\n",
      "And My court thou dishalth fancernd a mort umans count to some dead lord thee\n",
      "Iffarse am my wellow, you am moraty lip will\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9235, grad_fn=<DivBackward0>) \n",
      "\n",
      "be her for take the paice to by Kintilies; and will I came saine?\n",
      "\n",
      "MENENIUS:\n",
      "The troce.\n",
      "The the jailse storthy the hear comman: 'hatter's of the for gonen not, faid;\n",
      "Than in to with not in the come tim\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5606, grad_fn=<DivBackward0>) \n",
      "\n",
      "belatery!\n",
      "\n",
      "WARCIO:\n",
      "O cham ake pond the or and thou.\n",
      "\n",
      "KING RICHARD IIN:\n",
      "Thesius treates, we pride, for you have govence: and soul shiss.\n",
      "\n",
      "LORK:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bear the earpe of the pond soy me of is not lies, and is h\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8836, grad_fn=<DivBackward0>) \n",
      "\n",
      "be not poulse thee a fainst not him time as thy holil, and lild did the tous on trus my nowlll thou, and and that thou so.\n",
      "\n",
      "PETRUCHIO:\n",
      "Where live to good deging hanl to the bro, with I hands more thing\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9814, grad_fn=<DivBackward0>) \n",
      "\n",
      "bit slould the wid sicks tring hould deat of a contong the come.\n",
      "\n",
      "RORTIS:\n",
      "She hank'd but to thou may here notst thou with morrook your weantle mainty to she hing hall a hus trust to not Farnd panst sha\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.4662, grad_fn=<DivBackward0>) \n",
      "\n",
      "ber son Parther he the so men to need comest of me sope retite the loteetire this wingle,\n",
      "And andward from you, with could, to more will that this made.\n",
      "\n",
      "KINCENTIO: more in we us is unfuch the hink the\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7729, grad_fn=<DivBackward0>) \n",
      "\n",
      "best the with not him hand;\n",
      "What and shall the spe consulsem that on that lice bethine and for not not the yeant do-night to\n",
      "lay.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Plingsh the cant the will your the there of off the an\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5853, grad_fn=<DivBackward0>) \n",
      "\n",
      "ben drine all not this so me, what never hants, not prancure on the hach faren hink bad loss do must he enjeath'd trough cropding offer.\n",
      "\n",
      "BINGBROKE:\n",
      "The very I stopr so not you to fir to shall hould no\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6397, grad_fn=<DivBackward0>) \n",
      "\n",
      "ber crove none in tently him to so heir with such, for king.\n",
      "\n",
      "KING HENRY VINGS:\n",
      "The pray am gord to not nays!\n",
      "\n",
      "LADY IV:\n",
      "Nay,\n",
      "Will aglould have you mitrle's so me ould sided the shall heave to beat such\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8153, grad_fn=<DivBackward0>) \n",
      "\n",
      "bly, Han you this your to our fall conjitriend the scay froth alse not colfore toot but think therey:\n",
      "Come!\n",
      "\n",
      "Nurge.\n",
      "\n",
      "BUCHIOLI:\n",
      "Prome there himit so fim Wands:\n",
      "you go and be with heart from fould, and t\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8320, grad_fn=<DivBackward0>) \n",
      "\n",
      "bet the siend unglantlee.\n",
      "Which holib'd trumptuest'd it are on that of she ear, quittied have the still how you such sue promminy.\n",
      "\n",
      "ANTONIUS:\n",
      "Ay upon he such such all scorth'd brimes;\n",
      "And be chard, wit\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9737, grad_fn=<DivBackward0>) \n",
      "\n",
      "bever, I trope being; beat,.\n",
      "\n",
      "SARCLAND:\n",
      "Unvery,\n",
      "Of your gree of one now a fiscames him am fithery why, and their fiberter a wome, I have manish hold what I wist exsence for thy norrs lord;\n",
      "Lith these s\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6950, grad_fn=<DivBackward0>) \n",
      "\n",
      "ber butles, by lover I am the wack.\n",
      "\n",
      "ABANTY:\n",
      "A fair wortive rean never be coursetherful thy boy.\n",
      "\n",
      "LEONSO:\n",
      "This a maynatly weep the hard, it and see strue and sid the struclor: but sting a prom conter?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.4785, grad_fn=<DivBackward0>) \n",
      "\n",
      "bet:\n",
      "Which you shall we many, Inlubs wrain.\n",
      "\n",
      "RICHARDIUS:\n",
      "Con the hand-wind the monean shall I could the ssas swere him you himsering you have with for tarperly dey,\n",
      "And so shall foll.\n",
      "\n",
      "JUCKINGHAM:\n",
      "I ha\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6889, grad_fn=<DivBackward0>) \n",
      "\n",
      "bath, neess as I courle now my rancers his man the strantion upon retury like the are alazen in by unday the chows in exervingued!\n",
      "Whil most and weege!\n",
      "\n",
      "LATHY\n",
      "MORDY:\n",
      "I way\n",
      "Marriends to king\n",
      "You her fir\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.0818, grad_fn=<DivBackward0>) \n",
      "\n",
      "bly:\n",
      "But I will of he mooth,\n",
      "His makenger him thy fold to stay! thou\n",
      "with I would distle no, be respeal comb\n",
      "That which I would Young, my some: I greenterful the words hear but sponys best unculd as ha\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7191, grad_fn=<DivBackward0>) \n",
      "\n",
      "bold do good that God art you have that have a warm:\n",
      "Tybarmand kny king; comant him for our coming to from I have is in God\n",
      "the the jeady, be and stello, for to nother, how too wither propred her lilt \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8446, grad_fn=<DivBackward0>) \n",
      "\n",
      "bous mortter am amage, and would or some: despangent to the dother our say, and in his so laight werene thy fouch I here not sid fatard, fore.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Which of sed,\n",
      "Thou some and in hearing an\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8598, grad_fn=<DivBackward0>) \n",
      "\n",
      "bervent the dear'd in that heish ere peath and court slaught the king.\n",
      "\n",
      "DUCENTIO:\n",
      "And the comsiles\n",
      "What the many; he eye\n",
      "ser didger'd him that is pail me solded and it a litt, fatherturesh of they as t\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6757, grad_fn=<DivBackward0>) \n",
      "\n",
      "bres this look not it\n",
      "Suckery beated is boy\n",
      "That hood nast; is Kate conwich their bast\n",
      "chelovant we would wistal it will woure not you, it\n",
      "Wherefore sit?\n",
      "\n",
      "QUEEN MARGALO:\n",
      "Our swarther while eathard with\n",
      "\n",
      "\n",
      "\n",
      " tensor(2.0654, grad_fn=<DivBackward0>) \n",
      "\n",
      "bes, hath lead;\n",
      "I their a hume.\n",
      "\n",
      "VISTARE:\n",
      "My love let the dicher, and\n",
      "hold have him which his ladge.\n",
      "\n",
      "GLOUCESTER:\n",
      "She made there denest it is but ofser\n",
      "Yours tathing him sir, him! We in hence as yet ki\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8167, grad_fn=<DivBackward0>) \n",
      "\n",
      "brt the trucks,\n",
      "And to but stair, I have hood thee her the kied the serred;\n",
      "To pring my home she kint what say fay, where of langer am king, it thy pervers of brace,\n",
      "After\n",
      "As under shaber she shall enc\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6220, grad_fn=<DivBackward0>) \n",
      "\n",
      "bel--suigh\n",
      "The fail his farthe and wes and lice my hads my mores, lost the marry wonishas?\n",
      "\n",
      "FLOUCESTER:\n",
      "My lord to to-nithen, what life he such blaws pervands.\n",
      "\n",
      "CORIONA:\n",
      "How and firry joes aring good t\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.3306, grad_fn=<DivBackward0>) \n",
      "\n",
      "ble mine, shall the revelly the preatends.\n",
      "\n",
      "ESCALUS:\n",
      "This foot begnot thin felland that must true,\n",
      "Edwas a some the thee thee is I dead roself; and this stare;\n",
      "I will with-us and it should partor a gla\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7855, grad_fn=<DivBackward0>) \n",
      "\n",
      "ban we they strated,\n",
      "We'll con have when a more of of news?\n",
      "\n",
      "HENRESS:\n",
      "And me mers to are would where then as this con faven his greaminioural, his at the bries quip he with a him and bland vords,\n",
      "Ah no\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7152, grad_fn=<DivBackward0>) \n",
      "\n",
      "bentard the mody this put Rich\n",
      "Citis and be it his bartion\n",
      "Morst away well scaid the with bry card.\n",
      "\n",
      "KING RICHARD:\n",
      "Cetid;\n",
      "And I did he rest bean more boy.\n",
      "\n",
      "PETRUCHIO:\n",
      "\n",
      "LAMHIO:\n",
      "I spiar and somen are de \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9093, grad_fn=<DivBackward0>) \n",
      "\n",
      "been setted preatures of king.\n",
      "\n",
      "PETRUCHIO:\n",
      "We will.\n",
      "\n",
      "WARCIFINIUS:\n",
      "But sourse!\n",
      "\n",
      "PRONTES:\n",
      "Not the this good.\n",
      "\n",
      "PETRUSHORY:\n",
      "He tongure provils it absely?\n",
      "\n",
      "CLAULE:\n",
      "Why, stride here your beculd thy his foust\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8005, grad_fn=<DivBackward0>) \n",
      "\n",
      "by leathes, live his rakieve and this should this lerlly, foo come thee, I am frient for straused me sir: be heacth have with may you have it wore,\n",
      "but ever woblace to sould both now the geeming good t\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7820, grad_fn=<DivBackward0>) \n",
      "\n",
      "bely, mine cone.\n",
      "\n",
      "HENRY CULIET:\n",
      "You, have a stase it be that a viseed and a prome.\n",
      "\n",
      "First the wood of will ear when a deature from him now me to stay shall be let pluted mad fathat again.\n",
      "\n",
      "GRUMIO:\n",
      "Me m\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5286, grad_fn=<DivBackward0>) \n",
      "\n",
      "ban spipt sown\n",
      "Yea that as here me made in these shall day, some, I will now to how in time and I hoar take not to this that the gack you should her the seed's have all to the onnew and the toor'd why \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.4504, grad_fn=<DivBackward0>) \n",
      "\n",
      "bend there's not for the see my my landnor were my sin bears,\n",
      "And I that reparmant your Bomblet the jurched?\n",
      "\n",
      "SALINAT:\n",
      "And saughter, a dove thy love cold that a more to madame tale non.\n",
      "\n",
      "POLIAN:\n",
      "Who gr\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.4218, grad_fn=<DivBackward0>) \n",
      "\n",
      "brease in the sovers he the lisholf.\n",
      "\n",
      "KINGBROKE:\n",
      "Now the fall mensal in this love lantent lid door our the caminest you sears not I seet me a liver bear o'theicharded of you: they precomaced.\n",
      "\n",
      "KINGBROP\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7469, grad_fn=<DivBackward0>) \n",
      "\n",
      "bly you that grace?\n",
      "\n",
      "ANGELO:\n",
      "Eow nessesh firse.\n",
      "\n",
      "SICINIUS:\n",
      "Whry vore holy simes:\n",
      "Hath mad stant your thou am not brience\n",
      "To he\n",
      "Caralted. Gro.\n",
      "\n",
      "TRANIO:\n",
      "Now clerves I sicks from sin not me\n",
      "To son I sink \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.9365, grad_fn=<DivBackward0>) \n",
      "\n",
      "bid you thought have besold in come ank-poundior! thou lardis and I make well in things all fitter is all turson a lave be hone--mirsing, which eye,\n",
      "My falt of he make dost of of pruck to heave parce t\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5038, grad_fn=<DivBackward0>) \n",
      "\n",
      "by die that of me ervars,\n",
      "And will be both wasing him:\n",
      "More tried of of me of will there should stend\n",
      "On eyis to like me the sheart must thee eye;\n",
      "Of these is bries he compless anon, she lay is have li\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7890, grad_fn=<DivBackward0>) \n",
      "\n",
      "bellong the ear\n",
      "you king. Lare the seant my for me and to becrest of suself.\n",
      "\n",
      "AUFIDIUS:\n",
      "I remocked with are dorse; thou monicent servy; saness to thou holet;\n",
      "For this thy ondeld's duke thy well, it in \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8385, grad_fn=<DivBackward0>) \n",
      "\n",
      "by the trencets,\n",
      "And many\n",
      "hold,\n",
      "They wird not thou more, thy sleep, he weart, wrief, and the fyed,\n",
      "And to him would 'en my kirk, more a for of is therefore,\n",
      "Thou way their that will in sir me your unde\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.4712, grad_fn=<DivBackward0>) \n",
      "\n",
      "bestly, you,\n",
      "Ay,\n",
      "Some onour brother his gotter thee, it be bare go for all parse breat\n",
      "The gear that goter death\n",
      "To must madam, you more my would kints on your brother, gentle am to\n",
      "haph evens,\n",
      "That an\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8848, grad_fn=<DivBackward0>) \n",
      "\n",
      "be in I can end.\n",
      "\n",
      "ROMEO:\n",
      "What thou blood stops, you have messant:\n",
      "The enviclion: and yours are that with would king not is the\n",
      "death.\n",
      "\n",
      "NOMPEY:\n",
      "Your puntches your come, the was sir, our tong to this tha\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8222, grad_fn=<DivBackward0>) \n",
      "\n",
      "be herl thee slapee, you.\n",
      "\n",
      "KATHAM:\n",
      "Here if if you seet frape here is go mege a should for that are metter, he of merse for plairsious him go here of sient and honcaided will make you mee!\n",
      "\n",
      "POMPEY:\n",
      "Thre\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5732, grad_fn=<DivBackward0>) \n",
      "\n",
      "bers cach off\n",
      "to the parmorred what her swords thee spret and thing shree: fare with the good a pleat all of away?\n",
      "\n",
      "CLADY GREY:\n",
      "Your point to stray the garn and of haly it then for the it.\n",
      "\n",
      "FRIAR LAUGE\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8063, grad_fn=<DivBackward0>) \n",
      "\n",
      "boy, of good then, so sland though what that shall prouse not on you stawn of anamends you to art thee the pereater we shall promise that all reman and sue, as he'st the fall fore and whose it 'tis man\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6535, grad_fn=<DivBackward0>) \n",
      "\n",
      "be man to be a hear.\n",
      "\n",
      "LUCIO:\n",
      "The no blains must, their this was Becaid, all holdis mortor: but ster on undonger bucks there you will was will lage tell me of the poord: the very and he warm.\n",
      "\n",
      "ANTIO:\n",
      "Ha\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6702, grad_fn=<DivBackward0>) \n",
      "\n",
      "brence.\n",
      "\n",
      "BRANIA:\n",
      "The do heer\n",
      "With sent,\n",
      "Furse and men\n",
      "And their word ourself.\n",
      "\n",
      "GORIO:\n",
      "There the verwert of Hiself when then, good me proor heart you, by be there eince But the in lead, them care are to\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5609, grad_fn=<DivBackward0>) \n",
      "\n",
      "by thy sight be to, him Rominess\n",
      "He move my comes of to fellom all that what, comfides when field in vicer'd\n",
      "Why, the countench is evick. I'll confef to spisper liver upons.\n",
      "\n",
      "VIRY:\n",
      "I like you love of C\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7002, grad_fn=<DivBackward0>) \n",
      "\n",
      "bartutle,\n",
      "For strainorn I how gorth him here the purey come is the desinesmers, it should, and o' thesely from art my seased mister sut, spesent ther did who time his now to had?\n",
      "\n",
      "CLARENCE:\n",
      "Here under \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7543, grad_fn=<DivBackward0>) \n",
      "\n",
      "by curse\n",
      "With me law desence to now it the where playes the spartiends thou not satulion:\n",
      "Why gracess,\n",
      "I cunnts preit duke a in make and him the cies,\n",
      "And all the queen,\n",
      "The lies what bestrow's fair ou\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6915, grad_fn=<DivBackward0>) \n",
      "\n",
      "bel wangle.\n",
      "\n",
      "This in that it with by entrot Wastith heaving as not thy seemolnpy should to here the burse than with a ho shis the master poor burst in the sund sweilt and the mory?\n",
      "\n",
      "VOLULIA:\n",
      "I'll ethin\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6390, grad_fn=<DivBackward0>) \n",
      "\n",
      "belous me, Siry can Aulthes and do on the father'd who hour, doth the was to promes is the just not of my tongure more or the lords of the grieve nobed mine have thou domble to or no stay to should com\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8181, grad_fn=<DivBackward0>) \n",
      "\n",
      "bent holiss on the mound to speed frown,\n",
      "Halm thou and Henry fail,\n",
      "Benos hand of been.\n",
      "\n",
      "COMINIUS:\n",
      "As for the counted a good they Lallows and hath theep.\n",
      "Is light bethy brother the arous king, he we-bre\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6302, grad_fn=<DivBackward0>) \n",
      "\n",
      "bet for of love I say ever me sear night when thy can be be as look thou love nor me; to your love, your barrand\n",
      "There.\n",
      "\n",
      "PETRUCHIO:\n",
      "Nor my base a way down\n",
      "What that you, berewo resoly sight two letter,\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7411, grad_fn=<DivBackward0>) \n",
      "\n",
      "baint\n",
      "To so say dead say hath a daye,\n",
      "by a bal, my crave solvet my croces not I am he have not him That acled most our leady.\n",
      "\n",
      "Secous! honour a most as thy it of a good, good eveant we not your doing t\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6164, grad_fn=<DivBackward0>) \n",
      "\n",
      "but and thou at in should the maid.\n",
      "\n",
      "Firth the hear, not mory you, is hands,\n",
      "A life.\n",
      "\n",
      "TRUCHIO:\n",
      "Go pribant, love your conk, to coming death.\n",
      "\n",
      "HENRY VI LAURENT:\n",
      "Comest bod he forghes!\n",
      "Behise\n",
      "You be not o\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5608, grad_fn=<DivBackward0>) \n",
      "\n",
      "be shreat speak.\n",
      "\n",
      "ANCANUS:\n",
      "Ay, thus for you to-mery him.\n",
      "\n",
      "ISABELLAND:\n",
      "Pe lantias ear wich your part pouther them maur all the toold your veanture. Yee to nor onned my with him slanger is you seed hower\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.4897, grad_fn=<DivBackward0>) \n",
      "\n",
      "barder's more with sover.\n",
      "\n",
      "BETVSABALANLANA:\n",
      "And I hur would thou foo be from of into more be past looks of the have, whongutle to this one.\n",
      "\n",
      "MENENIUS:\n",
      "And must makes for more that I were un thou, spire\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5517, grad_fn=<DivBackward0>) \n",
      "\n",
      "baster,\n",
      "Not made this so jould his again,\n",
      "And I hurr and in all recrios of just to shall makes to you artain that charted and for not ste it in now pity a many thou so Mut and be mine upon not unjoy?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6381, grad_fn=<DivBackward0>) \n",
      "\n",
      "bant,\n",
      "But of mine, to perect,\n",
      "Unders there her haste.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Mauntor, mee to the truit, and fear fear shall ever have see, at abuse Can my but abseel,\n",
      "flo.\n",
      "\n",
      "Peplish ip in this face, I countl\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7267, grad_fn=<DivBackward0>) \n",
      "\n",
      "bjetian than puice, in spise so she so.\n",
      "\n",
      "KATHARINA:\n",
      "Should fast I hath stears: to that your up:\n",
      "What Bobounttret, and not this slick, mine nomblaum:\n",
      "My such of not thy wasd,--\n",
      "Prace, them are one be my\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.4941, grad_fn=<DivBackward0>) \n",
      "\n",
      "bre deser norm at here! soed such then and one an art to the victor:\n",
      "Ad dispone heart,\n",
      "The fart and what I well a mast follow upon Serves the wards,\n",
      "And seep thing, in the eld an some the be ot not a g\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.3033, grad_fn=<DivBackward0>) \n",
      "\n",
      "be our low;\n",
      "Where out.\n",
      "\n",
      "Second on unan dot lord,\n",
      "The greeply alamy your wordy, been in the lord; but, the have but sent amany, many that it musbury hands, on your speath,\n",
      "On Situders, make them that my\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5629, grad_fn=<DivBackward0>) \n",
      "\n",
      "bet! you aboran,\n",
      "Thy would be theo thy of thy is of your well contersess, as so.\n",
      "\n",
      "HENENT:\n",
      "Is a stain of Can or gasess mure metching it subuse, be meast have mine\n",
      "For mine than not Seen make he his hour\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7159, grad_fn=<DivBackward0>) \n",
      "\n",
      "but well to wifuting be me be the look this and being by angrange this wound for to me his love thus pray bodishal donilants,\n",
      "He aw though nong, we good served Grave here unwappranius\n",
      "Kuch so some:\n",
      "God\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.7350, grad_fn=<DivBackward0>) \n",
      "\n",
      "ber,\n",
      "Thy since; may, Kinner you she enselign, thy not lords traiden! thou have which now this most whills,\n",
      "The trance.' glant,\n",
      "Saye bolless thy macking the conder-mortain there sour past.\n",
      "To love brate\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8296, grad_fn=<DivBackward0>) \n",
      "\n",
      "by tire for theelle himself his come,\n",
      "The will how counds down and mulaning, to this will thou she this be while of shose is be mon does for is be be not of comes.\n",
      "\n",
      "ANTONIO:\n",
      "We will the foor is to him \n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6094, grad_fn=<DivBackward0>) \n",
      "\n",
      "ber,\n",
      "To begeates say his will as I darest blood;\n",
      "It in eound Yough to liber with the not both what hath, the nonrots, our.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Sillow and some our than the flood the love my more thress perss,\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.8034, grad_fn=<DivBackward0>) \n",
      "\n",
      "bad as she crine this fling death.\n",
      "\n",
      "CORIOLANUS:\n",
      "The still,\n",
      "So lind what that I more not sucut as my grighty, but fight\n",
      "Seenis, boor, I that in your arts, whot death, the was a stame approus,\n",
      "Not show b\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.4253, grad_fn=<DivBackward0>) \n",
      "\n",
      "be.\n",
      "I me you at the give then than that betise\n",
      "To tent?\n",
      "Pate forfing a sight them tume my comen my make thy counter theme my more like that me it: the with the strawh dutines sillong the sumb; and that\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.6427, grad_fn=<DivBackward0>) \n",
      "\n",
      "by he dian yours; so, and my were soffice, and so, a peir, son,\n",
      "The Came, what kildle not.\n",
      "\n",
      "COMINIUS:\n",
      "I sofillh, not fling their scernertion a part, with this's desire of a must you are can distul what\n",
      "\n",
      "\n",
      "\n",
      " tensor(1.5539, grad_fn=<DivBackward0>) \n",
      "\n",
      "beforther would our haten,\n",
      "This minry neightion of\n",
      "My trenove,\n",
      "This,\n",
      "This nither,\n",
      "And enderention,\n",
      "The can was of piet you frient,\n",
      "Come, may not the craven stear to brother will consuth.\n",
      "\n",
      "LUCHOSELLA:\n",
      "Y\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total = char_tensor(random_chunk())\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(chunk_len-1):\n",
    "        x = inp[i]\n",
    "        y_ = label[i]\n",
    "        y,hidden = model(x,hidden)\n",
    "        loss += criterion(y,y_.view(-1)) ## y_의 size가 0이 되면 안된다. \n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 ==0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능이 별로 안좋다 LSTM과 GRU도 해보자"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
