{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list\n",
    "\n",
    "# Parameter\n",
    "n_hidden = 128\n",
    "\n",
    "def make_batch(sentences):\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return Variable(torch.Tensor(input_batch)), Variable(torch.Tensor(output_batch)), Variable(torch.LongTensor(target_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention,self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size = n_class, hidden_size = n_hidden, dropout = 0.5)\n",
    "        self.dec_cell = nn.RNN(input_size = n_class, hidden_size = n_hidden, dropout = 0.5)\n",
    "        \n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden*2, n_class)\n",
    "        \n",
    "        \n",
    "    def forward(self, enc_inputs,hidden,dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0,1) \n",
    "        dec_inputs = dec_inputs.transpose(0,1)\n",
    "        \n",
    "        # enc_inputs : [n_step, batch_size, num_directions(=1)*n_hidden]\n",
    "        # enc_hidden : [num_layers(=1)*num_directions(=1), batch_size,n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs,hidden)\n",
    "        \n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = Variable(torch.empty([n_step,1,n_class]))\n",
    "\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden) # dec_inputs[i].unsqueeze : [1, batch_size, num_directions(=1)*n_hidden]\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [batch_size(=1), sep_len(=1), n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1)) # [n_step, batch_size, n_class] -> [batch_size,n_step, n_class]\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden] -> [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # model : [n_step, batch_size, n_class]\n",
    "            # torch.cat((dec_output,context),1) : [batch_size(=1),num_directions(=1) * n_hidden *2 ]\n",
    "            # self.out(torch.cat((dec_output,context),1)) : [batch_size(=1), n_class]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1)) # model : [seq_len(=5),batch_size(=1),n_class]\n",
    "\n",
    "\n",
    "        return model.transpose(0,1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs): \n",
    "        n_step = len(enc_outputs) # 각 enc_output의 seq_len에 대해서\n",
    "        attn_scores = Variable(torch.zeros(n_step)) # attn_scores : [n_step]\n",
    "        \n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "        \n",
    "        return F.softmax(attn_scores).view(1,1,-1)\n",
    "    \n",
    "    def get_att_score(self, dec_output, enc_output):\n",
    "        \n",
    "        score = self.attn(enc_output) # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1)) # inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, output_batch, target_batch = make_batch(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "hidden = Variable(torch.zeros(1,1,n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = Attention()\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0400 cost = 0.000429\n",
      "Epoch:  0800 cost = 0.000136\n",
      "Epoch:  1200 cost = 0.000067\n",
      "Epoch:  1600 cost = 0.000039\n",
      "Epoch:  2000 cost = 0.000025\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "    \n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch: ', '%04d' % (epoch +1), 'cost =', '{:.6f}'.format(loss))\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test_batch\n",
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "test_batch = Variable(torch.Tensor(test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 11])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1,keepdim=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show attention\n",
    "torch.Tensor(trained_attn).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attn, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
